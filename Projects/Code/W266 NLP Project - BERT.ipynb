{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Project\n",
    "\n",
    "### Adam Sayre & Erin Werner\n",
    "\n",
    "## BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the emoji and wordcloud packages to PATH\n",
    "import sys\n",
    "sys.path.insert(0,r\"./anaconda3/lib/python3.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd \n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import emoji\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "assert(nltk.download(\"treebank\"))\n",
    "from nltk.corpus import europarl_raw\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...  \n",
       "1                       i feel nor am i shamed by it  \n",
       "2  i had been feeling a little bit defeated by th...  \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...  \n",
       "4  i wouldnt feel burdened so that i would live m...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweet_data.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>E_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>rt usertaginstance usertaginstance oh fuck wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>usertaginstance imagine reaction guy called jj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           E_Content  \n",
       "0  rt usertaginstance usertaginstance oh fuck wro...  \n",
       "1                                        feel shamed  \n",
       "2  feeling little bit defeated steps faith would ...  \n",
       "3  usertaginstance imagine reaction guy called jj...  \n",
       "4  wouldnt feel burdened would live life testamen...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e = pd.read_csv(\"dataset(clean)_e.csv\") \n",
    "data_e.head()[['Emotion','Content','Original Content','E_Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>A_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>oh fuck did i wrote fil grinningfacewithsweat ...</td>\n",
       "      <td>b'RT @Davbingodav: @mcrackins Oh fuck.... did ...</td>\n",
       "      <td>b rt davbingodav mcrackins oh fuck wrote fil g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>i feel nor am i shamed by it</td>\n",
       "      <td>feel shamed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>i had been feeling a little bit defeated by th...</td>\n",
       "      <td>feeling little bit defeated steps faith would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>imagine if that reaction guy that called jj kf...</td>\n",
       "      <td>b\"@KSIOlajidebt imagine if that reaction guy t...</td>\n",
       "      <td>b ksiolajidebt imagine reaction guy called jj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>i wouldnt feel burdened so that i would live m...</td>\n",
       "      <td>wouldnt feel burdened would live life testamen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Emotion                                            Content  \\\n",
       "0  disappointed  oh fuck did i wrote fil grinningfacewithsweat ...   \n",
       "1  disappointed                       i feel nor am i shamed by it   \n",
       "2  disappointed  i had been feeling a little bit defeated by th...   \n",
       "3         happy  imagine if that reaction guy that called jj kf...   \n",
       "4  disappointed  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                    Original Content  \\\n",
       "0  b'RT @Davbingodav: @mcrackins Oh fuck.... did ...   \n",
       "1                       i feel nor am i shamed by it   \n",
       "2  i had been feeling a little bit defeated by th...   \n",
       "3  b\"@KSIOlajidebt imagine if that reaction guy t...   \n",
       "4  i wouldnt feel burdened so that i would live m...   \n",
       "\n",
       "                                           A_Content  \n",
       "0  b rt davbingodav mcrackins oh fuck wrote fil g...  \n",
       "1                                        feel shamed  \n",
       "2  feeling little bit defeated steps faith would ...  \n",
       "3  b ksiolajidebt imagine reaction guy called jj ...  \n",
       "4  wouldnt feel burdened would live life testamen...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_a = pd.read_csv(\"dataset(clean)_a.csv\") \n",
    "data_a.head()[['Emotion','Content','Original Content','A_Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disappointed    313714\n",
       "happy           301871\n",
       "angry           300990\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()  \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)     \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert_model(model, dataloader_train, dataloader_validation, optimizer, scheduler, epochs): \n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }       \n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "            \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        \n",
    "    return loss_train_avg, val_f1, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data.Emotion.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.Emotion.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(data.index.values, data.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data.label.values)\n",
    "\n",
    "#X_train_c, X_val_c, y_train_c, y_val_c = train_test_split(X_train_c, y_train_c, test_size=0.5, \n",
    "#                                                  random_state=42, stratify=y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>210693</td>\n",
       "      <td>210693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90297</td>\n",
       "      <td>90297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disappointed</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>219600</td>\n",
       "      <td>219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>94114</td>\n",
       "      <td>94114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>211309</td>\n",
       "      <td>211309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90562</td>\n",
       "      <td>90562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Content  Original Content\n",
       "Emotion      label data_type                           \n",
       "angry        2     train       210693            210693\n",
       "                   val          90297             90297\n",
       "disappointed 0     train       219600            219600\n",
       "                   val          94114             94114\n",
       "happy        1     train       211309            211309\n",
       "                   val          90562             90562"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data_type'] = ['not_set']*data.shape[0]\n",
    "\n",
    "data.loc[X_train_c, 'data_type'] = 'train'\n",
    "data.loc[X_val_c, 'data_type'] = 'val'\n",
    "\n",
    "data.groupby(['Emotion', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train_c = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='train'].Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_c = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='val'].Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train_c = encoded_data_train_c['input_ids']\n",
    "attention_masks_train_c = encoded_data_train_c['attention_mask']\n",
    "labels_train_c = torch.tensor(data[data.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val_c = encoded_data_val_c['input_ids']\n",
    "attention_masks_val_c = encoded_data_val_c['attention_mask']\n",
    "labels_val_c = torch.tensor(data[data.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train_c = TensorDataset(input_ids_train_c, attention_masks_train_c, labels_train_c)\n",
    "dataset_val_c = TensorDataset(input_ids_val_c, attention_masks_val_c, labels_val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2330db67ea14e8d80ae78cf53538d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c7943ac388404995a41a11bbbd2979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader_train_c = DataLoader(dataset_train_c, sampler=RandomSampler(dataset_train_c), batch_size=batch_size)\n",
    "dataloader_validation_c = DataLoader(dataset_val_c, sampler=SequentialSampler(dataset_val_c), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)              \n",
    "epochs = 1\n",
    "\n",
    "scheduler_c = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train_c)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affa2c7b8117439e869df58028880e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=213868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.31075673452883357\n",
      "Validation loss: 0.28929742172868833\n",
      "F1 Score (Weighted): 0.9207116909580677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tr_loss_c, bert_f1_c, bert_val_loss_c = train_bert_model(model, dataloader_train_c, dataloader_validation_c,\n",
    "                                                              optimizer, scheduler_c, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score of (0.85!)\n",
    "\n",
    "#### Original Uncleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Original_Content\"] = data[\"Original Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oc, X_val_oc, y_train_oc, y_val_oc = train_test_split(data.index.values, data.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data.label.values)\n",
    "\n",
    "#X_train_oc, X_val_oc, y_train_oc, y_val_oc = train_test_split(X_train_oc, y_train_oc, test_size=0.5, \n",
    "#                                                  random_state=42, stratify=y_train_oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Original Content</th>\n",
       "      <th>Original_Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>210693</td>\n",
       "      <td>210693</td>\n",
       "      <td>210693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90297</td>\n",
       "      <td>90297</td>\n",
       "      <td>90297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disappointed</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>219600</td>\n",
       "      <td>219600</td>\n",
       "      <td>219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>94114</td>\n",
       "      <td>94114</td>\n",
       "      <td>94114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>211309</td>\n",
       "      <td>211309</td>\n",
       "      <td>211309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90562</td>\n",
       "      <td>90562</td>\n",
       "      <td>90562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Content  Original Content  Original_Content\n",
       "Emotion      label data_type                                             \n",
       "angry        2     train       210693            210693            210693\n",
       "                   val          90297             90297             90297\n",
       "disappointed 0     train       219600            219600            219600\n",
       "                   val          94114             94114             94114\n",
       "happy        1     train       211309            211309            211309\n",
       "                   val          90562             90562             90562"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data_type'] = ['not_set']*data.shape[0]\n",
    "\n",
    "data.loc[X_train_oc, 'data_type'] = 'train'\n",
    "data.loc[X_val_oc, 'data_type'] = 'val'\n",
    "\n",
    "data.groupby(['Emotion', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train_oc = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='train'].Original_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_oc = tokenizer.batch_encode_plus(\n",
    "    data[data.data_type=='val'].Original_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train_oc = encoded_data_train_oc['input_ids']\n",
    "attention_masks_train_oc = encoded_data_train_oc['attention_mask']\n",
    "labels_train_oc = torch.tensor(data[data.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val_oc = encoded_data_val_oc['input_ids']\n",
    "attention_masks_val_oc = encoded_data_val_oc['attention_mask']\n",
    "labels_val_oc = torch.tensor(data[data.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train_oc = TensorDataset(input_ids_train_oc, attention_masks_train_oc, labels_train_oc)\n",
    "dataset_val_oc = TensorDataset(input_ids_val_oc, attention_masks_val_oc, labels_val_oc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader_train_oc = DataLoader(dataset_train_oc, sampler=RandomSampler(dataset_train_oc), batch_size=batch_size)\n",
    "dataloader_validation_oc = DataLoader(dataset_val_oc, sampler=SequentialSampler(dataset_val_oc),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)              \n",
    "epochs = 1\n",
    "\n",
    "scheduler_oc = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train_oc)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771c2330c765430898453f3c2c143b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=213868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.29519668717924713\n",
      "Validation loss: 0.27512661494702917\n",
      "F1 Score (Weighted): 0.9246183270067194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tr_loss_oc, bert_f1_oc, bert_val_loss_oc = train_bert_model(model, dataloader_train_oc, dataloader_validation_oc,\n",
    "                                                              optimizer, scheduler_oc, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Cleaned Data #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels_e = data_e.Emotion.unique()\n",
    "\n",
    "label_dict_e = {}\n",
    "for index, possible_label in enumerate(possible_labels_e):\n",
    "    label_dict_e[possible_label] = index\n",
    "label_dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e['label'] = data_e.Emotion.replace(label_dict_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_e, X_val_e, y_train_e, y_val_e = train_test_split(data_e.index.values, data_e.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data_e.label.values)\n",
    "\n",
    "#X_train_e, X_val_e, y_train_e, y_val_e = train_test_split(X_train_e, y_train_e, test_size=0.5, \n",
    "#                                                  random_state=42, stratify=y_train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>E_Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>210693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disappointed</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>94114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>211309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              E_Content\n",
       "Emotion      label data_type           \n",
       "angry        2     train         210693\n",
       "                   val            90297\n",
       "disappointed 0     train         219600\n",
       "                   val            94114\n",
       "happy        1     train         211309\n",
       "                   val            90562"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data__e = pd.DataFrame()\n",
    "data__e['Emotion'] = data_e['Emotion']\n",
    "data__e['label'] = data_e['label']\n",
    "data__e['E_Content'] = data_e['E_Content']\n",
    "\n",
    "data__e['data_type'] = ['not_set']*data__e.shape[0]\n",
    "\n",
    "data__e.loc[X_train_e, 'data_type'] = 'train'\n",
    "data__e.loc[X_val_e, 'data_type'] = 'val'\n",
    "\n",
    "data__e.groupby(['Emotion', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train_e = tokenizer.batch_encode_plus(\n",
    "    data__e[data__e.data_type=='train'].E_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_e = tokenizer.batch_encode_plus(\n",
    "    data__e[data__e.data_type=='val'].E_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train_e = encoded_data_train_e['input_ids']\n",
    "attention_masks_train_e = encoded_data_train_e['attention_mask']\n",
    "labels_train_e = torch.tensor(data__e[data__e.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val_e = encoded_data_val_e['input_ids']\n",
    "attention_masks_val_e = encoded_data_val_e['attention_mask']\n",
    "labels_val_e = torch.tensor(data__e[data__e.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train_e = TensorDataset(input_ids_train_e, attention_masks_train_e, labels_train_e)\n",
    "dataset_val_e = TensorDataset(input_ids_val_e, attention_masks_val_e, labels_val_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(label_dict_e),\n",
    "                                                      output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader_train_e = DataLoader(dataset_train_e, sampler=RandomSampler(dataset_train_e), batch_size=batch_size)\n",
    "dataloader_validation_e = DataLoader(dataset_val_e, sampler=SequentialSampler(dataset_val_e), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)            \n",
    "epochs = 1\n",
    "\n",
    "scheduler_e = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train_e)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cc155e2eb84b5daff1dcf19b3c95d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=213868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.3167731010424299\n",
      "Validation loss: 0.29601037087735566\n",
      "F1 Score (Weighted): 0.9154768232720168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tr_loss_e, bert_f1_e, bert_val_loss_e = train_bert_model(model, dataloader_train_e, dataloader_validation_e,\n",
    "                                                              optimizer, scheduler_e, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Cleaned Data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'disappointed': 0, 'happy': 1, 'angry': 2}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels_a = data_a.Emotion.unique()\n",
    "\n",
    "label_dict_a = {}\n",
    "for index, possible_label in enumerate(possible_labels_a):\n",
    "    label_dict_a[possible_label] = index\n",
    "label_dict_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a['label'] = data_a.Emotion.replace(label_dict_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(data_a.index.values, data_a.label.values, test_size=0.3, \n",
    "                                                  random_state=42, stratify=data_a.label.values)\n",
    "\n",
    "#X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X_train_a, y_train_a, test_size=0.5, \n",
    "#                                                  random_state=42, stratify=y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A_Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>210693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disappointed</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>94114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>211309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>90562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              A_Content\n",
       "Emotion      label data_type           \n",
       "angry        2     train         210693\n",
       "                   val            90297\n",
       "disappointed 0     train         219600\n",
       "                   val            94114\n",
       "happy        1     train         211309\n",
       "                   val            90562"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data__a = pd.DataFrame()\n",
    "data__a['Emotion'] = data_a['Emotion']\n",
    "data__a['label'] = data_a['label']\n",
    "data__a['A_Content'] = data_a['A_Content']\n",
    "\n",
    "data__a['data_type'] = ['not_set']*data__a.shape[0]\n",
    "\n",
    "data__a.loc[X_train_a, 'data_type'] = 'train'\n",
    "data__a.loc[X_val_a, 'data_type'] = 'val'\n",
    "\n",
    "data__a.groupby(['Emotion', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train_a = tokenizer.batch_encode_plus(\n",
    "    data__a[data__a.data_type=='train'].A_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_a = tokenizer.batch_encode_plus(\n",
    "    data__a[data__a.data_type=='val'].A_Content.values, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_attention_mask=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train_a = encoded_data_train_a['input_ids']\n",
    "attention_masks_train_a = encoded_data_train_a['attention_mask']\n",
    "labels_train_a = torch.tensor(data__a[data__a.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val_a = encoded_data_val_a['input_ids']\n",
    "attention_masks_val_a = encoded_data_val_a['attention_mask']\n",
    "labels_val_a = torch.tensor(data__a[data__a.data_type=='val'].label.values)\n",
    "\n",
    "dataset_train_a = TensorDataset(input_ids_train_a, attention_masks_train_a, labels_train_a)\n",
    "dataset_val_a = TensorDataset(input_ids_val_a, attention_masks_val_a, labels_val_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(label_dict_a),\n",
    "                                                      output_attentions=False,output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "dataloader_train_a = DataLoader(dataset_train_a, sampler=RandomSampler(dataset_train_a), batch_size=batch_size)\n",
    "dataloader_validation_a = DataLoader(dataset_val_a, sampler=SequentialSampler(dataset_val_a), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)            \n",
    "epochs = 1\n",
    "\n",
    "scheduler_a = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train_a)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f4bd6d6dbc47d0ae7d5ef208ec7789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=213868.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.309894040836024\n",
      "Validation loss: 0.2894129561177539\n",
      "F1 Score (Weighted): 0.9158085377793592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_tr_loss_a, bert_f1_a, bert_val_loss_a = train_bert_model(model, dataloader_train_a, dataloader_validation_a,\n",
    "                                                              optimizer, scheduler_a, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaning Method</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orig. Uncleaned</td>\n",
       "      <td>0.924618</td>\n",
       "      <td>0.295197</td>\n",
       "      <td>0.275127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orig. Cleaned</td>\n",
       "      <td>0.920712</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>0.289297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Custom Cleaned #1</td>\n",
       "      <td>0.915477</td>\n",
       "      <td>0.316773</td>\n",
       "      <td>0.296010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Custom Cleaned #2</td>\n",
       "      <td>0.915809</td>\n",
       "      <td>0.309894</td>\n",
       "      <td>0.289413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cleaning Method  F1 Score  Training Loss  Validation Loss\n",
       "0    Orig. Uncleaned  0.924618       0.295197         0.275127\n",
       "1      Orig. Cleaned  0.920712       0.310757         0.289297\n",
       "2  Custom Cleaned #1  0.915477       0.316773         0.296010\n",
       "3  Custom Cleaned #2  0.915809       0.309894         0.289413"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_f1 = [bert_f1_oc, bert_f1_c, bert_f1_e, bert_f1_a]\n",
    "b_tr_loss = [bert_tr_loss_oc, bert_tr_loss_c, bert_tr_loss_e, bert_tr_loss_a]\n",
    "b_val_loss = [bert_val_loss_oc, bert_val_loss_c, bert_val_loss_e, bert_val_loss_a]\n",
    "b_values = ['Orig. Uncleaned', 'Orig. Cleaned', 'Custom Cleaned #1', 'Custom Cleaned #2']\n",
    "b_df = pd.DataFrame()\n",
    "b_df['Cleaning Method'] = b_values\n",
    "b_df['F1 Score'] = b_f1\n",
    "b_df['Training Loss'] = b_tr_loss\n",
    "b_df['Validation Loss'] = b_val_loss\n",
    "b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_p37",
   "language": "python",
   "name": "tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
